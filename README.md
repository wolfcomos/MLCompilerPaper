# ML Compiler Papers & Blogs
Study and Interview preps for ML Compilers/Systems

## Auto Tune:
MetaTune: Meta-Learning Based Cost Model for Fast and Efficient Auto-tuning Frameworks: https://arxiv.org/abs/2102.04199 \
A Survey on Compiler Autotuning using Machine Learning: https://arxiv.org/pdf/1801.04405

## Graph Optimizations:
Operator Fusion in XLA: Analysis and Evaluation: https://arxiv.org/abs/2301.13062

## Graph Scheduler:
A memory-aware scheduling framework for streaming applications on multicore systems: https://pure.manchester.ac.uk/ws/portalfiles/portal/85778437 \
Parallel Scheduling of DAGs under Memory Constraints: https://ieeexplore.ieee.org/document/8425174 \
Multilevel Algorithms for Acyclic Partitioning of Directed Acyclic Graphs: https://inria.hal.science/hal-02306566/document \
On Optimizing the Communication of Model Parallelism: https://arxiv.org/abs/2211.05322 \
Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning: https://arxiv.org/abs/2201.12023

## Hardware Design Space Exploration:
CoSA: Scheduling by Constrained Optimization for Spatial Accelerators: https://arxiv.org/abs/2105.01898 \
Timeloop: A Systematic Approach to DNN Accelerator Evaluation: https://accelergy.mit.edu/timeloop.pdf \
Chipyard: Integrated Design, Simulation, and Implementation Framework for Custom SoCs: https://ieeexplore.ieee.org/document/9099108 \
Gemini: Mapping and Architecture Co-exploration for Large-scale DNN Chiplet Accelerators: https://arxiv.org/abs/2312.16436

## e2e ML Compiler Frameworks
TinyIREE: An ML Execution Environment for Embedded Systems from Compilation to Deployment: https://arxiv.org/abs/2205.14479 \
Compiling ONNX Neural Network Models Using MLIR: https://arxiv.org/abs/2008.08272 \
AMD AIE/AIR Design for Xilinx AI engine: https://www.xilinx.com/content/dam/xilinx/publications/presentations/leveraging-mlir-to-design-for-aie-fpga-2023.pdf \
TVM: An Automated End-to-End Optimizing Compiler for Deep Learning: https://arxiv.org/abs/1802.04799 \
TPU-MLIR: https://github.com/sophgo/tpu-mlir

## Datalayout
High Performance Zero-Memory Overhead Direct Convolutions: https://arxiv.org/pdf/1809.10170 \
Triton intro: https://superjomn.github.io/posts/triton-mlir-publish/




